{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea31f96-d2e1-4c6a-932b-03cd708e32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Business Analytics Model Development Started\n",
      "üìä Module 4 Assignment: Bank Transactions Analysis\n"
     ]
    }
   ],
   "source": [
    "# Business Analytics Model: Bank Transactions Analysis\n",
    "# Module 4 Assignment\n",
    "\n",
    "\"\"\"\n",
    "Assignment Overview:\n",
    "- Develop business analytics model using cleaned bank transactions data\n",
    "- Implement customer segmentation and behavior prediction\n",
    "- Evaluate model performance with relevant metrics\n",
    "- Document entire process in Jupyter Notebook\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Business Analytics Model Development Started\")\n",
    "print(\"üìä Module 4 Assignment: Bank Transactions Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf25306-7f72-4aa2-8b70-12425d9329fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 1: DATA LOADING AND FINAL PREPARATION\n",
      "‚ö†Ô∏è Cleaned data not found. Loading raw data...\n",
      "‚ö†Ô∏è src folder not found. Using raw data as-is.\n",
      "\n",
      "üìã Dataset Overview:\n",
      "Shape: (1048567, 9)\n",
      "Columns: ['TransactionID', 'CustomerID', 'CustomerDOB', 'CustGender', 'CustLocation', 'CustAccountBalance', 'TransactionDate', 'TransactionTime', 'TransactionAmount (INR)']\n",
      "\n",
      "üîç Final Data Quality Check:\n",
      "Missing values: 7017\n",
      "Duplicate rows: 0\n",
      "\n",
      "üìä Sample Data (First 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerDOB</th>\n",
       "      <th>CustGender</th>\n",
       "      <th>CustLocation</th>\n",
       "      <th>CustAccountBalance</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>TransactionTime</th>\n",
       "      <th>TransactionAmount (INR)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>C5841053</td>\n",
       "      <td>10/1/94</td>\n",
       "      <td>F</td>\n",
       "      <td>JAMSHEDPUR</td>\n",
       "      <td>17819.05</td>\n",
       "      <td>2/8/16</td>\n",
       "      <td>143207</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>C2142763</td>\n",
       "      <td>4/4/57</td>\n",
       "      <td>M</td>\n",
       "      <td>JHAJJAR</td>\n",
       "      <td>2270.69</td>\n",
       "      <td>2/8/16</td>\n",
       "      <td>141858</td>\n",
       "      <td>27999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>C4417068</td>\n",
       "      <td>26/11/96</td>\n",
       "      <td>F</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>17874.44</td>\n",
       "      <td>2/8/16</td>\n",
       "      <td>142712</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TransactionID CustomerID CustomerDOB CustGender CustLocation  \\\n",
       "0            T1   C5841053     10/1/94          F   JAMSHEDPUR   \n",
       "1            T2   C2142763      4/4/57          M      JHAJJAR   \n",
       "2            T3   C4417068    26/11/96          F       MUMBAI   \n",
       "\n",
       "   CustAccountBalance TransactionDate  TransactionTime  \\\n",
       "0            17819.05          2/8/16           143207   \n",
       "1             2270.69          2/8/16           141858   \n",
       "2            17874.44          2/8/16           142712   \n",
       "\n",
       "   TransactionAmount (INR)  \n",
       "0                     25.0  \n",
       "1                  27999.0  \n",
       "2                    459.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"üîß STEP 1: DATA LOADING AND FINAL PREPARATION\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Paths\n",
    "cleaned_csv_path = r\"C:\\Users\\FORUM\\Desktop\\Nexford Submissions for MSDA\\bank_transactions_ready.csv\"\n",
    "raw_csv_path = r\"C:\\Users\\FORUM\\Desktop\\Nexford Submissions for MSDA\\bank_transactions.csv\"\n",
    "src_path = r\"C:\\Users\\FORUM\\Desktop\\Nexford Submissions for MSDA\\src\"\n",
    "\n",
    "# Step 1: Load cleaned CSV if it exists\n",
    "if os.path.exists(cleaned_csv_path):\n",
    "    df = pd.read_csv(cleaned_csv_path)\n",
    "    print(f\"‚úÖ Cleaned data loaded successfully: {df.shape}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cleaned data not found. Loading raw data...\")\n",
    "    df_raw = pd.read_csv(raw_csv_path)\n",
    "    \n",
    "    # Step 2: Attempt to load cleaning modules if they exist\n",
    "    if os.path.exists(src_path):\n",
    "        sys.path.append(src_path)\n",
    "        try:\n",
    "            from data_cleaning import clean_data\n",
    "            from feature_engineering import engineer_features\n",
    "            df = engineer_features(clean_data(df_raw))\n",
    "            print(f\"‚úÖ Raw data processed successfully: {df.shape}\")\n",
    "        except ModuleNotFoundError:\n",
    "            print(\"‚ö†Ô∏è data_cleaning or feature_engineering modules not found. Using raw data as-is.\")\n",
    "            df = df_raw\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è src folder not found. Using raw data as-is.\")\n",
    "        df = df_raw\n",
    "\n",
    "# Step 3: Dataset overview\n",
    "print(\"\\nüìã Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Step 4: Data quality checks\n",
    "print(\"\\nüîç Final Data Quality Check:\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Step 5: Display sample\n",
    "print(\"\\nüìä Sample Data (First 3 rows):\")\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed8d181-946c-4736-a650-16daac2dee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ STEP 2: BUSINESS OBJECTIVES AND IMPLEMENTATION PLAN\n",
      "\n",
      "BUSINESS ANALYTICS OBJECTIVES:\n",
      "\n",
      "1. CUSTOMER SEGMENTATION\n",
      "   - Group customers based on transaction behavior\n",
      "   - Identify high-value customer segments\n",
      "   - Enable targeted marketing strategies\n",
      "\n",
      "2. TRANSACTION BEHAVIOR PREDICTION\n",
      "   - Predict high-value transactions\n",
      "   - Identify patterns for fraud detection\n",
      "   - Forecast customer transaction patterns\n",
      "\n",
      "3. CUSTOMER LIFETIME VALUE ANALYSIS\n",
      "   - Segment customers by potential value\n",
      "   - Identify retention opportunities\n",
      "   - Optimize resource allocation\n",
      "\n",
      "MODELING APPROACH:\n",
      "1. Unsupervised Learning: K-means clustering for customer segmentation\n",
      "2. Supervised Learning: Classification for high-value transaction prediction\n",
      "3. Ensemble Methods: Random Forest for feature importance analysis\n",
      "\n",
      "\n",
      "üìã STEP-BY-STEP IMPLEMENTATION PLAN:\n",
      "\n",
      "PHASE 1: DATA PREPARATION\n",
      "‚úì Load and validate cleaned data\n",
      "‚úì Feature selection for modeling\n",
      "‚úì Data normalization and encoding\n",
      "\n",
      "PHASE 2: CUSTOMER SEGMENTATION (K-means Clustering)\n",
      "- Select clustering features\n",
      "- Determine optimal number of clusters\n",
      "- Apply K-means algorithm\n",
      "- Analyze and interpret segments\n",
      "\n",
      "PHASE 3: HIGH-VALUE TRANSACTION PREDICTION\n",
      "- Create binary classification target\n",
      "- Split data into training/testing sets\n",
      "- Train multiple classification models\n",
      "- Evaluate and select best performer\n",
      "\n",
      "PHASE 4: MODEL EVALUATION & BUSINESS INSIGHTS\n",
      "- Analyze model performance metrics\n",
      "- Extract feature importance\n",
      "- Generate business recommendations\n",
      "- Document findings and limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define Business Objectives and Implementation Plan\n",
    "print(\"üéØ STEP 2: BUSINESS OBJECTIVES AND IMPLEMENTATION PLAN\")\n",
    "\n",
    "business_objectives = \"\"\"\n",
    "BUSINESS ANALYTICS OBJECTIVES:\n",
    "\n",
    "1. CUSTOMER SEGMENTATION\n",
    "   - Group customers based on transaction behavior\n",
    "   - Identify high-value customer segments\n",
    "   - Enable targeted marketing strategies\n",
    "\n",
    "2. TRANSACTION BEHAVIOR PREDICTION\n",
    "   - Predict high-value transactions\n",
    "   - Identify patterns for fraud detection\n",
    "   - Forecast customer transaction patterns\n",
    "\n",
    "3. CUSTOMER LIFETIME VALUE ANALYSIS\n",
    "   - Segment customers by potential value\n",
    "   - Identify retention opportunities\n",
    "   - Optimize resource allocation\n",
    "\n",
    "MODELING APPROACH:\n",
    "1. Unsupervised Learning: K-means clustering for customer segmentation\n",
    "2. Supervised Learning: Classification for high-value transaction prediction\n",
    "3. Ensemble Methods: Random Forest for feature importance analysis\n",
    "\"\"\"\n",
    "\n",
    "print(business_objectives)\n",
    "\n",
    "# Step-by-step implementation plan\n",
    "implementation_plan = \"\"\"\n",
    "üìã STEP-BY-STEP IMPLEMENTATION PLAN:\n",
    "\n",
    "PHASE 1: DATA PREPARATION\n",
    "‚úì Load and validate cleaned data\n",
    "‚úì Feature selection for modeling\n",
    "‚úì Data normalization and encoding\n",
    "\n",
    "PHASE 2: CUSTOMER SEGMENTATION (K-means Clustering)\n",
    "- Select clustering features\n",
    "- Determine optimal number of clusters\n",
    "- Apply K-means algorithm\n",
    "- Analyze and interpret segments\n",
    "\n",
    "PHASE 3: HIGH-VALUE TRANSACTION PREDICTION\n",
    "- Create binary classification target\n",
    "- Split data into training/testing sets\n",
    "- Train multiple classification models\n",
    "- Evaluate and select best performer\n",
    "\n",
    "PHASE 4: MODEL EVALUATION & BUSINESS INSIGHTS\n",
    "- Analyze model performance metrics\n",
    "- Extract feature importance\n",
    "- Generate business recommendations\n",
    "- Document findings and limitations\n",
    "\"\"\"\n",
    "\n",
    "print(implementation_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0707f-1e41-4672-8b39-1292267b4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Selection and Preprocessing\n",
    "print(\"‚öôÔ∏è STEP 3: FEATURE SELECTION AND PREPROCESSING\")\n",
    "\n",
    "# Select features for modeling\n",
    "modeling_features = [\n",
    "    'TransactionAmount (INR)', \n",
    "    'CustAccountBalance',\n",
    "    'CustomerAge',\n",
    "    'TransactionHour',\n",
    "    'BalanceToTransactionRatio',\n",
    "    'IsMetroCity',\n",
    "    'HighValueTransaction'\n",
    "]\n",
    "\n",
    "# Only use available features\n",
    "available_features = [col for col in modeling_features if col in df.columns]\n",
    "print(f\"Available features for modeling: {available_features}\")\n",
    "\n",
    "# Create modeling dataset\n",
    "X = df[available_features].copy()\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns\n",
    "print(f\"Categorical columns to encode: {categorical_cols.tolist()}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Handle missing values if any\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Final modeling dataset shape: {X.shape}\")\n",
    "print(\"\\nüìä Modeling Features Summary:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Feature correlation analysis\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a8837-e6ca-4171-b80c-f462d56e6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Customer Segmentation using K-means Clustering\n",
    "print(\"üë• STEP 4: CUSTOMER SEGMENTATION MODEL\")\n",
    "\n",
    "# Select features for clustering (remove target variable if present)\n",
    "clustering_features = [col for col in available_features if col != 'HighValueTransaction']\n",
    "X_cluster = X[clustering_features].copy()\n",
    "\n",
    "# Standardize features for clustering\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "# Determine optimal number of clusters using Elbow Method\n",
    "print(\"üîç Determining optimal number of clusters...\")\n",
    "\n",
    "wcss = []  # Within-cluster sum of squares\n",
    "silhouette_scores = []\n",
    "cluster_range = range(2, 8)\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    if k > 1:  # Silhouette score requires at least 2 clusters\n",
    "        score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "# Plot Elbow Method\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow curve\n",
    "ax1.plot(cluster_range, wcss, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters')\n",
    "ax1.set_ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "ax1.set_title('Elbow Method for Optimal K')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette scores\n",
    "ax2.plot(range(2, 8), silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Clusters')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Scores for Different K Values')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal K (based on elbow and silhouette score)\n",
    "optimal_k = 4  # You can adjust this based on the plots\n",
    "print(f\"üéØ Selected optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "# Apply K-means with optimal K\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df['CustomerSegment'] = cluster_labels\n",
    "X['CustomerSegment'] = cluster_labels\n",
    "\n",
    "print(f\"‚úÖ Customer segmentation completed with {optimal_k} clusters\")\n",
    "print(f\"Cluster distribution:\\n{df['CustomerSegment'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552b576-887b-44f5-b8a3-f836e9073b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Customer Segment Analysis\n",
    "print(\"üìä STEP 5: CUSTOMER SEGMENT ANALYSIS\")\n",
    "\n",
    "# Analyze characteristics of each cluster\n",
    "segment_analysis = df.groupby('CustomerSegment').agg({\n",
    "    'TransactionAmount (INR)': ['mean', 'median', 'count'],\n",
    "    'CustAccountBalance': ['mean', 'median'],\n",
    "    'CustomerAge': ['mean', 'median'],\n",
    "    'TransactionHour': ['mean', 'median'],\n",
    "    'BalanceToTransactionRatio': ['mean', 'median'],\n",
    "    'IsMetroCity': 'mean'  # Proportion in metro cities\n",
    "}).round(2)\n",
    "\n",
    "print(\"üìà Customer Segment Profiles:\")\n",
    "display(segment_analysis)\n",
    "\n",
    "# Visualize segment characteristics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Average Transaction Amount by Segment\n",
    "segment_analysis[('TransactionAmount (INR)', 'mean')].plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Average Transaction Amount by Segment')\n",
    "axes[0,0].set_ylabel('Amount (INR)')\n",
    "\n",
    "# Plot 2: Average Account Balance by Segment\n",
    "segment_analysis[('CustAccountBalance', 'mean')].plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "axes[0,1].set_title('Average Account Balance by Segment')\n",
    "axes[0,1].set_ylabel('Balance (INR)')\n",
    "\n",
    "# Plot 3: Average Age by Segment\n",
    "segment_analysis[('CustomerAge', 'mean')].plot(kind='bar', ax=axes[0,2], color='gold')\n",
    "axes[0,2].set_title('Average Customer Age by Segment')\n",
    "axes[0,2].set_ylabel('Age')\n",
    "\n",
    "# Plot 4: Metro City Proportion by Segment\n",
    "segment_analysis[('IsMetroCity', 'mean')].plot(kind='bar', ax=axes[1,0], color='lightcoral')\n",
    "axes[1,0].set_title('Metro City Proportion by Segment')\n",
    "axes[1,0].set_ylabel('Proportion')\n",
    "\n",
    "# Plot 5: Transaction Count by Segment\n",
    "segment_analysis[('TransactionAmount (INR)', 'count')].plot(kind='bar', ax=axes[1,1], color='violet')\n",
    "axes[1,1].set_title('Transaction Count by Segment')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "\n",
    "# Plot 6: Balance to Transaction Ratio\n",
    "segment_analysis[('BalanceToTransactionRatio', 'mean')].plot(kind='bar', ax=axes[1,2], color='orange')\n",
    "axes[1,2].set_title('Balance to Transaction Ratio by Segment')\n",
    "axes[1,2].set_ylabel('Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create segment profiles\n",
    "segment_profiles = \"\"\"\n",
    "üéØ CUSTOMER SEGMENT PROFILES:\n",
    "\n",
    "Segment 0: [Description based on your analysis]\n",
    "- Average Transaction: ‚Çπ{}\n",
    "- Average Balance: ‚Çπ{}\n",
    "- Typical Age: {}\n",
    "- Metro City: {}%\n",
    "\n",
    "Segment 1: [Description based on your analysis]\n",
    "- Average Transaction: ‚Çπ{}\n",
    "- Average Balance: ‚Çπ{}\n",
    "- Typical Age: {}\n",
    "- Metro City: {}%\n",
    "\n",
    "Segment 2: [Description based on your analysis]\n",
    "- Average Transaction: ‚Çπ{}\n",
    "- Average Balance: ‚Çπ{}\n",
    "- Typical Age: {}\n",
    "- Metro City: {}%\n",
    "\n",
    "Segment 3: [Description based on your analysis]\n",
    "- Average Transaction: ‚Çπ{}\n",
    "- Average Balance: ‚Çπ{}\n",
    "- Typical Age: {}\n",
    "- Metro City: {}%\n",
    "\"\"\".format(\n",
    "    segment_analysis[('TransactionAmount (INR)', 'mean')].iloc[0],\n",
    "    segment_analysis[('CustAccountBalance', 'mean')].iloc[0],\n",
    "    segment_analysis[('CustomerAge', 'mean')].iloc[0],\n",
    "    segment_analysis[('IsMetroCity', 'mean')].iloc[0] * 100,\n",
    "    # Repeat for other segments...\n",
    ")\n",
    "\n",
    "print(segment_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35160137-7f49-43f5-bf53-95f31ed949d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: High-Value Transaction Prediction\n",
    "print(\"üí∞ STEP 6: HIGH-VALUE TRANSACTION PREDICTION MODEL\")\n",
    "\n",
    "# Prepare data for classification\n",
    "if 'HighValueTransaction' in df.columns:\n",
    "    # Use HighValueTransaction as target\n",
    "    y = df['HighValueTransaction']\n",
    "else:\n",
    "    # Create target variable (top 20% transactions by amount)\n",
    "    high_value_threshold = df['TransactionAmount (INR)'].quantile(0.8)\n",
    "    y = (df['TransactionAmount (INR)'] > high_value_threshold).astype(int)\n",
    "    df['HighValueTransaction'] = y\n",
    "\n",
    "print(f\"Target variable distribution:\\n{y.value_counts()}\")\n",
    "print(f\"High-value transactions: {y.sum()} ({y.mean()*100:.1f}% of total)\")\n",
    "\n",
    "# Prepare features (exclude target and segment for training)\n",
    "X_classification = X.drop(['HighValueTransaction', 'CustomerSegment'], axis=1, errors='ignore')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_classification, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")\n",
    "\n",
    "# Train multiple classification models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "model_results = {}\n",
    "\n",
    "print(\"üöÄ Training classification models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüìä Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name} Results:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"   Precision: {precision:.3f}\")\n",
    "    print(f\"   Recall:    {recall:.3f}\")\n",
    "    print(f\"   F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# Compare model performance\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['accuracy', 'precision', 'recall', 'f1_score']]\n",
    "\n",
    "print(\"\\nüèÜ MODEL PERFORMANCE COMPARISON:\")\n",
    "display(results_df.sort_values('f1_score', ascending=False))\n",
    "\n",
    "# Select best model based on F1-score\n",
    "best_model_name = results_df['f1_score'].idxmax()\n",
    "best_model = model_results[best_model_name]['model']\n",
    "print(f\"\\nüéØ Best Performing Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f52208-f119-45f7-816d-622277ff7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Evaluation and Interpretation\n",
    "print(\"üìà STEP 7: MODEL EVALUATION AND INTERPRETATION\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "print(f\"\\nüîç Detailed Evaluation for {best_model_name}:\")\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not High Value', 'High Value'],\n",
    "            yticklabels=['Not High Value', 'High Value'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Classification Report\n",
    "plt.subplot(1, 2, 2)\n",
    "cr = classification_report(y_test, y_pred_best, output_dict=True)\n",
    "cr_df = pd.DataFrame(cr).transpose()\n",
    "sns.heatmap(cr_df.iloc[:-1, :-1], annot=True, cmap='viridis')\n",
    "plt.title('Classification Report Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Feature Importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(\"\\nüéØ FEATURE IMPORTANCE ANALYSIS:\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_classification.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "    plt.title(f'Top 10 Feature Importance - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d36f968-ff54-4dca-8247-092e1e9bd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Business Insights and Recommendations\n",
    "print(\"üí° STEP 8: BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
    "\n",
    "# Generate business insights\n",
    "total_customers = len(df)\n",
    "high_value_customers = df[df['HighValueTransaction'] == 1]['CustomerID'].nunique()\n",
    "\n",
    "insights = f\"\"\"\n",
    "üìä BUSINESS INSIGHTS FROM MODEL ANALYSIS:\n",
    "\n",
    "1. CUSTOMER SEGMENTATION RESULTS:\n",
    "   - {optimal_k} distinct customer segments identified\n",
    "   - Segment sizes vary from {df['CustomerSegment'].value_counts().min()} to {df['CustomerSegment'].value_counts().max()} customers\n",
    "   - Clear differentiation in transaction patterns and balances\n",
    "\n",
    "2. HIGH-VALUE TRANSACTION PREDICTION:\n",
    "   - Best model: {best_model_name} with F1-score of {model_results[best_model_name]['f1_score']:.3f}\n",
    "   - Can predict high-value transactions with {model_results[best_model_name]['precision']:.1%} precision\n",
    "   - {high_value_customers} unique high-value customers identified ({high_value_customers/total_customers*100:.1f}% of total)\n",
    "\n",
    "3. KEY PREDICTORS OF HIGH-VALUE TRANSACTIONS:\n",
    "\"\"\"\n",
    "\n",
    "if 'feature_importance' in locals():\n",
    "    top_features = feature_importance.head(3)['feature'].tolist()\n",
    "    insights += f\"   - {top_features[0]}\\n   - {top_features[1]}\\n   - {top_features[2]}\\n\"\n",
    "\n",
    "insights += \"\"\"\n",
    "üéØ STRATEGIC RECOMMENDATIONS:\n",
    "\n",
    "1. TARGETED MARKETING:\n",
    "   - Develop segment-specific marketing campaigns\n",
    "   - Focus on high-value customer retention\n",
    "   - Personalize communication based on segment characteristics\n",
    "\n",
    "2. RISK MANAGEMENT:\n",
    "   - Use prediction model for transaction monitoring\n",
    "   - Implement alerts for unusual high-value transactions\n",
    "   - Enhance fraud detection capabilities\n",
    "\n",
    "3. CUSTOMER SERVICE OPTIMIZATION:\n",
    "   - Allocate resources based on customer value\n",
    "   - Develop segment-specific service protocols\n",
    "   - Implement proactive engagement for high-value segments\n",
    "\n",
    "4. PRODUCT DEVELOPMENT:\n",
    "   - Create tailored financial products for each segment\n",
    "   - Develop premium services for high-value customers\n",
    "   - Optimize digital banking features based on usage patterns\n",
    "\"\"\"\n",
    "\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7a3e4-6ed8-4e9b-8138-1597a14cd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Model Deployment Preparation\n",
    "print(\"üöÄ STEP 9: MODEL DEPLOYMENT PREPARATION\")\n",
    "\n",
    "# Save the trained models and preprocessing objects\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, '../models/high_value_prediction_model.pkl')\n",
    "\n",
    "# Save preprocessing objects\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(label_encoders, '../models/label_encoders.pkl')\n",
    "\n",
    "# Save cluster model\n",
    "joblib.dump(kmeans, '../models/customer_segmentation_model.pkl')\n",
    "\n",
    "print(\"‚úÖ Models saved successfully:\")\n",
    "print(\"   - ../models/high_value_prediction_model.pkl\")\n",
    "print(\"   - ../models/scaler.pkl\") \n",
    "print(\"   - ../models/label_encoders.pkl\")\n",
    "print(\"   - ../models/customer_segmentation_model.pkl\")\n",
    "\n",
    "# Create prediction function for demonstration\n",
    "def predict_high_value_transaction(features):\n",
    "    \"\"\"\n",
    "    Predict if a transaction is high-value\n",
    "    \"\"\"\n",
    "    # Load model and preprocessing objects\n",
    "    model = joblib.load('../models/high_value_prediction_model.pkl')\n",
    "    scaler = joblib.load('../models/scaler.pkl')\n",
    "    \n",
    "    # Preprocess features and make prediction\n",
    "    features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "    prediction = model.predict(features_scaled)\n",
    "    probability = model.predict_proba(features_scaled)\n",
    "    \n",
    "    return prediction[0], probability[0][1]\n",
    "\n",
    "print(\"\\nüéØ Model Deployment Ready!\")\n",
    "print(\"   Models can be integrated into banking systems for:\")\n",
    "print(\"   - Real-time transaction monitoring\")\n",
    "print(\"   - Customer segmentation dashboards\")\n",
    "print(\"   - Marketing campaign optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf34b6-26a5-4485-8f3c-e5035ef284e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Final Summary and Documentation\n",
    "print(\"üìù STEP 10: FINAL SUMMARY AND DOCUMENTATION\")\n",
    "\n",
    "# Generate model performance summary\n",
    "summary = f\"\"\"\n",
    "üéâ BUSINESS ANALYTICS MODEL DEVELOPMENT COMPLETE\n",
    "\n",
    "MODELING SUMMARY:\n",
    "\n",
    "1. DATA PREPARATION:\n",
    "   - Records Processed: {len(df):,}\n",
    "   - Features Used: {len(available_features)}\n",
    "   - Data Quality: {((len(df) - df.isnull().sum().sum()) / len(df) * 100):.1f}% complete\n",
    "\n",
    "2. CUSTOMER SEGMENTATION:\n",
    "   - Algorithm: K-means Clustering\n",
    "   - Optimal Clusters: {optimal_k}\n",
    "   - Silhouette Score: {silhouette_score(X_scaled, cluster_labels):.3f}\n",
    "   - Segments Identified: {df['CustomerSegment'].nunique()}\n",
    "\n",
    "3. HIGH-VALUE TRANSACTION PREDICTION:\n",
    "   - Best Model: {best_model_name}\n",
    "   - Accuracy: {model_results[best_model_name]['accuracy']:.3f}\n",
    "   - Precision: {model_results[best_model_name]['precision']:.3f}\n",
    "   - Recall: {model_results[best_model_name]['recall']:.3f}\n",
    "   - F1-Score: {model_results[best_model_name]['f1_score']:.3f}\n",
    "\n",
    "4. BUSINESS IMPACT:\n",
    "   - Enabled data-driven customer segmentation\n",
    "   - Provided high-value transaction prediction capability\n",
    "   - Delivered actionable insights for marketing and risk management\n",
    "   - Established foundation for advanced analytics\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Integrate models into production systems\n",
    "2. Develop real-time monitoring dashboards\n",
    "3. Implement A/B testing for model improvements\n",
    "4. Expand model features with additional customer data\n",
    "\n",
    "MODEL LIMITATIONS:\n",
    "- Based on historical transaction data only\n",
    "- Does not include external economic factors\n",
    "- Requires regular retraining with new data\n",
    "- Performance may vary with changing customer behavior\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save model results to file\n",
    "results_output = {\n",
    "    'segmentation_performance': {\n",
    "        'optimal_clusters': optimal_k,\n",
    "        'silhouette_score': silhouette_score(X_scaled, cluster_labels),\n",
    "        'cluster_distribution': df['CustomerSegment'].value_counts().to_dict()\n",
    "    },\n",
    "    'classification_performance': {\n",
    "        'best_model': best_model_name,\n",
    "        'accuracy': model_results[best_model_name]['accuracy'],\n",
    "        'precision': model_results[best_model_name]['precision'],\n",
    "        'recall': model_results[best_model_name]['recall'],\n",
    "        'f1_score': model_results[best_model_name]['f1_score']\n",
    "    },\n",
    "    'business_metrics': {\n",
    "        'total_customers': total_customers,\n",
    "        'high_value_customers': high_value_customers,\n",
    "        'high_value_percentage': (high_value_customers / total_customers * 100)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../reports/model_performance_metrics.json', 'w') as f:\n",
    "    json.dump(results_output, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model performance metrics saved to '../reports/model_performance_metrics.json'\")\n",
    "print(\"\\nüéä MODULE 4 ASSIGNMENT COMPLETED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36882fbc-1eb0-4f07-8d3a-ce1b732626ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new model notebook and files to GitHub\n",
    "git add notebooks/business_analytics_model.ipynb\n",
    "git add models/\n",
    "git add reports/model_performance_metrics.json\n",
    "\n",
    "git commit -m \"Add Module 4: Business analytics model with customer segmentation and prediction\"\n",
    "git push origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
